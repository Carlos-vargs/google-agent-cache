# üöÄ Google Generative AI Chat API ‚Äî Context Cache

[![Express](https://img.shields.io/badge/Express-5-black?logo=express)](#)
[![Google Generative AI](https://img.shields.io/badge/Google%20Generative%20AI-Gemini-4285F4?logo=google)](#)
[![License: ISC](https://img.shields.io/badge/License-ISC-blue.svg)](./LICENSE)
[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg)](#)

Un servidor Express listo para chatear con Gemini usando Context Cache: sube tus fuentes una vez, crea un cach√© remoto y √∫salo como contexto base en tus conversaciones. ‚ú®

---

## üìö Tabla de contenidos

- üß† Qu√© es y c√≥mo funciona
- ‚öôÔ∏è Instalaci√≥n r√°pida
- üîê Configuraci√≥n (.env)
- üß™ Healthcheck
- üß© API (endpoints)
- üõ†Ô∏è CLI (comandos)
- üì¶ Estructura sugerida
- üìò Ejemplos
- ‚ùì FAQ y tips

---

## üß© API (endpoints)

### 1Ô∏è‚É£ Context Cache

```http
POST /api/cache/setup
```

```json
{
  "filePath": "string",
  "mimeType": "string",
  "displayName": "string",
  "model": "string",
  "ttlSeconds": "number",
  "systemInstruction": "string",
  "cacheDisplayName": "string"
}
```

> Sube el archivo, espera el procesamiento, crea el cach√© remoto y guarda el nombre en cache.json

```http
GET /api/cache
```

> Informaci√≥n del cach√© guardado

```http
DELETE /api/cache
```

> Elimina la referencia local (no borra el cach√© remoto)

---

### 2Ô∏è‚É£ Chat

```http
POST /api/chat
```

```json
{
  "question": "string", // requerido
  "cache": "string", // opcional, nombre del cach√©
  "model": "string", // opcional, modelo a usar
  "files": [
    // opcional, rutas de archivos locales o URLs
    "data/cache_sources/mi-archivo.pdf"
  ]
}
```

> Usa el cach√© como contexto base y puede adjuntar archivos adicionales (PDF, TXT, MD) como rutas locales o URLs.

---

### 3Ô∏è‚É£ Healthcheck

```http
GET /health
```

> Devuelve `{ status: 'ok' }` si el servidor est√° activo.

- PORT=3000

Modelos: usa uno que soporte createCachedContent (por ejemplo models/gemini-2.5-pro).

---

## üß™ Healthcheck

GET /health ‚Üí { status: 'ok' }

---

## üß© API (endpoints)

### 1Ô∏è‚É£ Context Cache

```http
POST /api/cache/setup
```

```json
{
  "filePath": "string",
  "mimeType": "string",
  "displayName": "string",
  "model": "string",
  "ttlSeconds": "number",
  "systemInstruction": "string",
  "cacheDisplayName": "string"
}
```

> Sube el archivo, espera el procesamiento, crea el cach√© remoto y guarda el nombre en cache.json

```http
GET /api/cache
```

> Informaci√≥n del cach√© guardado

```http
DELETE /api/cache
```

> Elimina la referencia local (no borra el cach√© remoto)

---

### 2Ô∏è‚É£ Chat

```http
POST /api/chat
```

```json
{
  "question": "string",
  "context": "string",
  "files": [
    {
      "path": "string",
      "mimeType": "string",
      "displayName": "string"
    }
  ]
}
```

> Usa el cach√© como contexto base + contexto/archivos opcionales

```http
POST /api/chat/upload (multipart/form-data)
```

**fields:**

- `question` (requerido)
- `context` (opcional)

**files:**

- m√∫ltiples PDFs/TXT/MD en el campo `files`; se suben a Gemini y se a√±aden al prompt

---

## üõ†Ô∏è CLI (comandos)

| Comando      | Descripci√≥n                           | Uso                                                                            |
| ------------ | ------------------------------------- | ------------------------------------------------------------------------------ |
| list-models  | Lista modelos y m√©todos soportados    | `npm run list-models`                                                          |
| setup-cache  | Sube fuentes y crea un Context Cache  | `npm run setup-cache -- [dir] [displayName] [model] [ttl] [systemInstruction]` |
| list-caches  | Lista cach√©s remotos                  | `npm run list-caches`                                                          |
| delete-cache | Elimina un cach√© remoto por name o ID | `npm run delete-cache -- cachedContents/XXX` o `npm run delete-cache -- XXX`   |

Tip: usa `npm run list-caches` para copiar el campo name exacto.

---

## üì¶ Estructura sugerida

```
.
‚îú‚îÄ data/
‚îÇ  ‚îî‚îÄ cache_sources/      # Tus fuentes (.pdf, .txt, .md, ...)
‚îú‚îÄ src/
‚îÇ  ‚îú‚îÄ cli/                # Scripts CLI
‚îÇ  ‚îî‚îÄ server.js           # Servidor Express
‚îú‚îÄ cache.json             # Nombre del cach√© guardado
‚îî‚îÄ .env                   # GEMINI_API_KEY
```

---

## üìò Ejemplos

JSON (ruta local en el servidor):

```bash
curl -X POST http://localhost:3000/api/chat \
  -H 'Content-Type: application/json' \
  -d '{
    "question": "¬øQu√© documentos faltan?",
    "context": "Embarque MX-001",
    "files": [{
      "path": "data/cache_sources/mi-archivo.pdf",
      "mimeType": "application/pdf",
      "displayName": "mi-archivo.pdf"
    }]
  }'
```

Subiendo PDFs desde el cliente (multipart/form-data):

```bash
curl -X POST http://localhost:3000/api/chat/upload \
  -F "question=¬øQu√© BL aplica?" \
  -F "context=Embarque MX-001" \
  -F "files=@data/cache_sources/ejemplo1.pdf;type=application/pdf" \
  -F "files=@data/cache_sources/ejemplo2.pdf;type=application/pdf"
```

---

## ‚ùì FAQ y tips

- Aseg√∫rate de que el modelo soporte createCachedContent.
- Si no tienes .env.example, crea .env y a√±ade GEMINI_API_KEY.
- Puedes recrear el cach√© cuando caduque usando la CLI.

---

Hecho con ‚ù§Ô∏è para desarrolladores que necesitan respuestas con contexto persistente. ‚ú®
